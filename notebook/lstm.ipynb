{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load Gensim Word2Vec model correctly\n",
    "w2v_model = Word2Vec.load(\"D:/Projects/Emotion Detection/model/word2vec_model.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the datatset\n",
    "df=pd.read_csv('dataset\\combined_emotion.csv')\n",
    "\n",
    "# Extract text and labels\n",
    "texts = df[\"sentence\"].values\n",
    "labels = df[\"emotion\"].values\n",
    "\n",
    "# Encode labels into integers\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)  # Convert labels to numerical values\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 1, ..., 2, 1, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sad'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422746 entries, 0 to 422745\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   sentence  422746 non-null  object\n",
      " 1   emotion   422746 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "max_words = 10000  # Vocabulary size\n",
    "max_len = 100      # Maximum sequence length\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Padding sequences to ensure uniform input size\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post', truncating='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=128, input_length=max_len),  # Word embeddings\n",
    "    LSTM(128, return_sequences=True),  # LSTM layer\n",
    "    Dropout(0.5),\n",
    "    LSTM(64),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(np.unique(labels)), activation='softmax')  # Output layer (adjust based on label count)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "#model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10569/10569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1369s\u001b[0m 130ms/step - accuracy: 0.3369 - loss: 1.5762 - val_accuracy: 0.3404 - val_loss: 1.5759\n",
      "Epoch 2/10\n",
      "\u001b[1m10569/10569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1455s\u001b[0m 138ms/step - accuracy: 0.3380 - loss: 1.5764 - val_accuracy: 0.3404 - val_loss: 1.5759\n",
      "Epoch 3/10\n",
      "\u001b[1m10569/10569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1148s\u001b[0m 109ms/step - accuracy: 0.3362 - loss: 1.5760 - val_accuracy: 0.3404 - val_loss: 1.5758\n",
      "Epoch 4/10\n",
      "\u001b[1m10569/10569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4065s\u001b[0m 385ms/step - accuracy: 0.3379 - loss: 1.5738 - val_accuracy: 0.3404 - val_loss: 1.5759\n",
      "Epoch 5/10\n",
      "\u001b[1m10569/10569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1268s\u001b[0m 120ms/step - accuracy: 0.3378 - loss: 1.5760 - val_accuracy: 0.3404 - val_loss: 1.5758\n",
      "Epoch 6/10\n",
      "\u001b[1m10569/10569\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1178s\u001b[0m 111ms/step - accuracy: 0.3380 - loss: 1.5751 - val_accuracy: 0.3404 - val_loss: 1.5759\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_pad, y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_pad, y_test),\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2643/2643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 30ms/step - accuracy: 0.3398 - loss: 1.5762\n",
      "Test Accuracy: 0.3404\n",
      "\u001b[1m2643/2643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 32ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test_pad)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Decode predicted labels\n",
    "predicted_emotions = label_encoder.inverse_transform(predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(sentence):\n",
    "    # Load tokenizer and label encoder\n",
    "    #with open(\"tokenizer.pkl\", \"rb\") as file:\n",
    "        #tokenizer = pickle.load(file)\n",
    "\n",
    "    #with open(\"label_encoder.pkl\", \"rb\") as file:\n",
    "        #label_encoder = pickle.load(file)\n",
    "\n",
    "    # Preprocess input sentence\n",
    "    sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "    # Load model\n",
    "    #model = tf.keras.models.load_model(\"emotion_lstm_model.h5\")\n",
    "\n",
    "    # Make prediction\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    predicted_emotion = label_encoder.inverse_transform([predicted_label])[0]\n",
    "\n",
    "    return predicted_emotion\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "The weather is wonderful today! : 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "I am feeling really sad and lonely. : 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "What an exciting game we had last night! : 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "I can't believe how much I've learned this year! : 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "I was so angry during the meeting today. : 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "I can't believe how everything turned out today, it's a bit overwhelming. : 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "I guess I'm doing okay, but it's not as good as I hoped. : 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "That was such a fantastic presentation, even though I made some mistakes. : 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "I'm so glad I made it through the day, but I'm exhausted! : 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "I can't stop thinking about how much better things could have been. : 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "It was a long day, but I had a lot of fun! : 2\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "My cat died today. : 2\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "example_sentences =  [\n",
    "        \"The weather is wonderful today!\",\n",
    "        \"I am feeling really sad and lonely.\",\n",
    "        \"What an exciting game we had last night!\",\n",
    "        \"I can't believe how much I've learned this year!\",\n",
    "        \"I was so angry during the meeting today.\",\n",
    "        \"I can't believe how everything turned out today, it's a bit overwhelming.\",\n",
    "        \"I guess I'm doing okay, but it's not as good as I hoped.\",\n",
    "        \"That was such a fantastic presentation, even though I made some mistakes.\",\n",
    "        \"I'm so glad I made it through the day, but I'm exhausted!\",\n",
    "        \"I can't stop thinking about how much better things could have been.\",\n",
    "        \"It was a long day, but I had a lot of fun!\",\n",
    "        \"My cat died today.\"\n",
    "    ]\n",
    "\n",
    "for i in example_sentences:\n",
    "    print(i,\":\",predict_emotion(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
